{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# sklearn\n",
    "This is a machine learning library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "source": [
    "## Standard Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "hide_input": false,
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; margin-left:350px; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; margin-left:350px; }</style>\"))\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "pd.set_option( 'display.notebook_repr_html', False)  # render Series and DataFrame as text, not HTML\n",
    "pd.set_option( 'display.max_column', 10)    # number of columns\n",
    "pd.set_option( 'display.max_rows', 10)     # number of rows\n",
    "pd.set_option( 'display.width', 90)        # number of characters per row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## The Library\n",
    "sklearn **does not automatically import its subpackages**. Therefore all subpakcages must be specifically loaded before use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model    import LinearRegression\n",
    "from sklearn.pipeline        import make_pipeline\n",
    "from sklearn.preprocessing   import Imputer\n",
    "from sklearn.preprocessing   import PolynomialFeatures\n",
    "from sklearn.metrics         import *\n",
    "\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Data\n",
    "Generate 100 rows of data, with 3x features (X1,X2,X3), and one dependant variable (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100  # number of samples\n",
    "I = 5  # intercept value\n",
    "E = np.random.randint( 1,20, n)  # Error\n",
    "X1 = np.random.randint( 1,n+1, n)\n",
    "X2 = np.random.randint( 1,n+1, n)\n",
    "X3 = np.random.randint( 1,n+1, n)\n",
    "Y = 0.1*X1 + 0.2*X2 + 0.3*X3 + E + I\n",
    "mydf = pd.DataFrame({\n",
    "    'Y':Y,\n",
    "    'X1':X1,\n",
    "    'X2':X2,\n",
    "    'X3':X3\n",
    "})\n",
    "mydf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   X1  X2  X3     Y\n",
       "0  92  18  33  31.7\n",
       "1  58  89  34  52.8\n",
       "2  39  23  80  56.5\n",
       "3  49  60  60  58.9\n",
       "4  91  81  64  67.5"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Method 1: Split One Dataframe Into Two (Train & Test)\n",
    "\n",
    "```\n",
    "traindf, testdf = train_test_split( df, test_size=, random_state= ) \n",
    " # random_state : seed number (integer), optional\n",
    " # test_size    : fraction of 1, 0.2 means 20%\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "traindf, testdf = train_test_split(mydf,test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print (len(traindf))\n",
    "print (len(testdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: DataFrame in X,Y, split into x_train/test, y_train/test\n",
    "```\n",
    "x_train, x_test, y_train, y_test = train_test_split( X,Y, test_size=, random_state= )\n",
    " # random_state : seed number (integer), optional\n",
    " # test_size    : fraction of 1, 0.2 means 20%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split DataFrame into X and Y First**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['X1','X2','X3']\n",
    "X = mydf[feature_cols]\n",
    "Y = mydf.Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then Split X/Y into x_train/test, y_train/test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( X,Y, test_size=0.2, random_state=25)\n",
    "print (len(x_train))\n",
    "print (len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Transform\n",
    "This can be used as part of feature engineering, to introduce new features for data that seems to fit with quadradic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Data\n",
    "Data must be 2-D before polynomial features can be applied. Code below convert 1D array into 2D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5]])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4, 5])\n",
    "X = x[:,np.newaxis]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree 1\n",
    "One Degree means maintain original features. No new features is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 4.],\n",
       "       [ 5.]])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PolynomialFeatures(degree=1, include_bias=False).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree 2\n",
    "Degree-1 original   feature:  x  \n",
    "Degree-2 additional features:  x^2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   1.],\n",
       "       [  2.,   4.],\n",
       "       [  3.,   9.],\n",
       "       [  4.,  16.],\n",
       "       [  5.,  25.]])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PolynomialFeatures(degree=2, include_bias=False).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree 3\n",
    "Degree-1 original   feature:  x  \n",
    "Degree-2 additional features:  x^2  \n",
    "Degree-3 additional features:  x^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.,    1.,    1.],\n",
       "       [   2.,    4.,    8.],\n",
       "       [   3.,    9.,   27.],\n",
       "       [   4.,   16.,   64.],\n",
       "       [   5.,   25.,  125.]])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PolynomialFeatures(degree=3, include_bias=False).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree 4\n",
    "Degree-1 original   feature:  x  \n",
    "Degree-2 additional features:  x^2  \n",
    "Degree-3 additional features:  x^3  \n",
    "Degree-3 additional features:  x^4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.,    1.,    1.,    1.],\n",
       "       [   2.,    4.,    8.,   16.],\n",
       "       [   3.,    9.,   27.,   81.],\n",
       "       [   4.,   16.,   64.,  256.],\n",
       "       [   5.,   25.,  125.,  625.]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PolynomialFeatures(degree=4, include_bias=False).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   x1  x2\n",
       "0   1   6\n",
       "1   2   7\n",
       "2   3   8\n",
       "3   4   9\n",
       "4   5  10"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame( {'x1': [1, 2, 3, 4, 5 ],\n",
    "                   'x2': [6, 7, 8, 9, 10]})\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree 2\n",
    "```\n",
    "Degree-1 original   features:  x1,     x2  \n",
    "Degree-2 additional features:  x1^2,   x2^2,   x1:x2 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.,    6.,    1.,    6.,   36.],\n",
       "       [   2.,    7.,    4.,   14.,   49.],\n",
       "       [   3.,    8.,    9.,   24.,   64.],\n",
       "       [   4.,    9.,   16.,   36.,   81.],\n",
       "       [   5.,   10.,   25.,   50.,  100.]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PolynomialFeatures(degree=2, include_bias=False).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree 3\n",
    "```\n",
    "Degree-1 original   features:  x1,       x2  \n",
    "Degree-2 additional features:  x1^2,     x2^2,   x1:x2 \n",
    "Degree-3 additional features:  x1^3,     x2^3    x1:x2^2    x2:x1^2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1.,     6.,     1.,     6.,    36.,     1.,     6.,    36.,\n",
       "          216.],\n",
       "       [    2.,     7.,     4.,    14.,    49.,     8.,    28.,    98.,\n",
       "          343.],\n",
       "       [    3.,     8.,     9.,    24.,    64.,    27.,    72.,   192.,\n",
       "          512.],\n",
       "       [    4.,     9.,    16.,    36.,    81.,    64.,   144.,   324.,\n",
       "          729.],\n",
       "       [    5.,    10.,    25.,    50.,   100.,   125.,   250.,   500.,\n",
       "         1000.]])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PolynomialFeatures(degree=3, include_bias=False).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation of Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "X = np.array([[ nan, 0,   3  ],\n",
    "              [ 3,   7,   9  ],\n",
    "              [ 3,   5,   2  ],\n",
    "              [ 4,   nan, 6  ],\n",
    "              [ 8,   8,   1  ]])\n",
    "\n",
    "y = np.array([14, 16, -1,  8, -5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.5,  0. ,  3. ],\n",
       "       [ 3. ,  7. ,  9. ],\n",
       "       [ 3. ,  5. ,  2. ],\n",
       "       [ 4. ,  5. ,  6. ],\n",
       "       [ 8. ,  8. ,  1. ]])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = Imputer(strategy='mean')\n",
    "X2 = imp.fit_transform(X)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 16, -1,  8, -5])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   x1  x2\n",
       " 0   1   6\n",
       " 1   2   7\n",
       " 2   3   8\n",
       " 3   4   9\n",
       " 4   5  10, array([14, 16, -1,  8, -5]))"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With any of the preceding examples, it can quickly become tedious to do the transformations by hand, especially if you wish to string together multiple steps. For example, we might want a processing pipeline that looks something like this:\n",
    "\n",
    "- **Impute** missing values using the mean  \n",
    "- **Transform** features to quadratic  \n",
    "- **Fit** a linear regression  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = make_pipeline (\n",
    "    Imputer(strategy='mean'),\n",
    "    PolynomialFeatures(degree=2),\n",
    "    LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 16 -1  8 -5]\n",
      "[ 14.  16.  -1.   8.  -5.]\n"
     ]
    }
   ],
   "source": [
    "my_model.fit( X, y) # train the model\n",
    "print (y)\n",
    "print (my_model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model    import LinearRegression\n",
    "from sklearn.metrics        import mean_absolute_error, mean_squared_error\n",
    "import statsmodels.api   as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## The Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Emulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200  # number of samples\n",
    "I = 250  # intercept value\n",
    "E = np.random.randint( 1,20, n)  # Error\n",
    "X1 = np.random.randint( 1,n+1, n)\n",
    "X2 = np.random.randint( 1,n+1, n)\n",
    "X3 = np.random.randint( 1,n+1, n)\n",
    "Y = 0.1*X1 + 0.2*X2 + 0.3*X3 + E + I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put All Data In pandas DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    X1   X2   X3      Y\n",
       "0  154  102   81  324.1\n",
       "1  193    2   68  305.1\n",
       "2   35  162  177  343.0\n",
       "3  155  160  110  334.5\n",
       "4  127  127    6  306.9"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf = pd.DataFrame({\n",
    "    'Y':Y,\n",
    "    'X1':X1,\n",
    "    'X2':X2,\n",
    "    'X3':X3\n",
    "})\n",
    "mydf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure there is **no col-linearity** among the features used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colleration Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'corr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-288-f6e663ca97f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'corr'"
     ]
    }
   ],
   "source": [
    "X.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(X, alpha=0.2, figsize=(6, 6), diagonal='hist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(X.corr())\n",
    "plt.xticks(range(len(X.columns)), X.columns)\n",
    "plt.yticks(range(len(X.columns)), X.columns)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling (scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Features and Dependent Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['X1','X2','X3']\n",
    "X = mydf[feature_cols]\n",
    "Y = mydf.Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Data Into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,testX,trainY,testY = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()   # create linear regression object\n",
    "lm.fit( trainX, trainY )  # train the model using training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze The Model\n",
    "#### Intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(zip(X.columns, lm.coef_)), columns=['features','coef'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R-Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTrain = lm.predict( trainX )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score( trainY, predTrain )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "#### Run Prediction On Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPred = lm.predict( trainX )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error( trainY, trainPred )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error( trainY, trainPred )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt( mean_squared_error( trainY, trainPred ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPred = lm.predict( testX )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error( testY, testPred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error( testY, testPred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt( mean_squared_error( testY, testPred ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling (statsmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "Splitting data into training set and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf, testdf = train_test_split(mydf, test_size=0.2)\n",
    "trainX,testX,trainY,testY = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create The Model - Equation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = smf.ols(formula='Y ~ X1 + X2 + X3', data=traindf).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create The Model - Array Method\n",
    "**intercept** is not included in OLS modeling by default. Hence need to use add_constant() to training dataset in order to display intercept estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = sm.add_constant(trainX)     # this add new column of all value 1\n",
    "fit2 = smf.OLS(trainY, trainX).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (fit2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "x = 10 * rng.rand(50)\n",
    "2*x+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 - Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Data\n",
    "Plot looks like polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([4, 2, 1, 3, 7])\n",
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Built The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare The Data**  \n",
    "X needs to be at least 2D. Increase the dimension with newaxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x[:, np.newaxis]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit and Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = LinearRegression().fit(X, y)\n",
    "pred = fit.predict(X)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 - Linear Regression with Polynomial Basis Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([4, 2, 1, 3, 7])\n",
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Method - Use Pipeline\n",
    "This method **avoid manually** creating engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_model = make_pipeline( PolynomialFeatures(3), LinearRegression())\n",
    "poly_model.fit( X,y)\n",
    "pred2 = poly_model.predict(X)\n",
    "## plot\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x,pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative Method - Use Transform\n",
    "This method involve create a PolynomialFeatures object, transform original data (X) with more engineered features according to degree chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X2 = poly.fit_transform(X)\n",
    "fit2 = LinearRegression().fit(X2, y)\n",
    "pred2 = fit2.predict(X2)\n",
    "## plot\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x,pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage of using skcikit-learn package is that it has this particular method selection, works more or less like backward selection (not exactly), and is called **Recursive Feature**. How it works:\n",
    "\n",
    "- Model run with all variables, weight is assigned to each variable\n",
    "- Variable with smallest weight will be pruned from next iteration\n",
    "- Run the model again till the number of desired features is left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SVR(kernel='linear')       # we are using linear model\n",
    "selector = RFE (estimator, 2, step=1)  # we want just 2 features\n",
    "selector = selector.fit(X,Y)           # execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "944px",
    "left": "0px",
    "right": "1043.45px",
    "top": "110px",
    "width": "401px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
